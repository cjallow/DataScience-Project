{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to taxi trip data\n",
    "\n",
    "The taxicabs of New York City come in two varieties: yellow and green.\n",
    "\n",
    "Taxis painted canary __yellow__ (medallion taxis) are able to pick up passengers *__anywhere__ in the five boroughs.* \n",
    "\n",
    "Those painted apple __green__ (street hail livery vehicles,or commonly known as boro taxis), which began to appear in August 2013, are *allowed to pick up passengers in __Upper Manhattan__, the Bronx, Brooklyn, Queens (excluding LaGuardia Airport and John F. Kennedy International Airport), and Staten Island.*\n",
    "\n",
    "--from wiki['Taxicabs of New York City'](https://en.wikipedia.org/wiki/Taxicabs_of_New_York_City)--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "We will use \n",
    "\n",
    "    `Yellow Taxi Trip Data from 2010 to 2015` \n",
    "    `Green Taxi Trip Data from 2013 to 2014`\n",
    "    \n",
    "    \n",
    "which are accessible through __NYC OpenData__:\n",
    "\n",
    "[2010 Yellow Taxi Trip Data](https://data.cityofnewyork.us/Transportation/2010-Yellow-Taxi-Trip-Data/ry9a-ubra)\n",
    "168,994,353 rows\n",
    "\n",
    "[2011 Yellow Taxi Trip Data](https://data.cityofnewyork.us/Transportation/2011-Yellow-Taxi-Trip-Data/jr6k-xwua)\n",
    "135,335,924 rows \n",
    "\n",
    "[2012 Yellow Taxi Trip Data](https://data.cityofnewyork.us/Transportation/2012-Yellow-Taxi-Trip-Data/fd5y-xikb)\n",
    "167,331,308 rows\n",
    "\n",
    "[2013 Yellow Taxi Trip Data](https://data.cityofnewyork.us/Transportation/2013-Yellow-Taxi-Trip-Data/7rnv-m532)\n",
    "173,179,759 rows\n",
    "\n",
    "[2013 Green Taxi Trip Data](https://data.cityofnewyork.us/Transportation/2013-Green-Taxi-Trip-Data/ghpb-fpea)\n",
    "about 1.21M rows\n",
    "\n",
    "[2014 Yellow Taxi Trip Data](https://data.cityofnewyork.us/Transportation/2015-Yellow-Taxi-Trip-Data/ba8s-jw6u)\n",
    "165,114,361 rows\n",
    "\n",
    "[2014 Green Taxi Trip Data](https://data.cityofnewyork.us/Transportation/2014-Green-Taxi-Trip-Data/2np7-5jsg)\n",
    "about 15.8M rows\n",
    "\n",
    "The total data size for five years is too big to be handled by our computer, so we decided to take a subset - sample - based on the payment related criteria. \n",
    "\n",
    "The subset sampleing criteria:\n",
    "\n",
    "For all data, we will only consider trip records - rows - provided by **[VeriFone, inc.](http://www.verifone.com/industries/taxi/)**- one of major companies that provides taxi payment system. These records are marked as `VTS` on `vendorid` (or `vendor_id`) column. \n",
    "\n",
    "For each year, we will sample 100,000 records. Among the 100,000 sample, 50% will be cash payment records and the other 50% will be credit payment record. For the years 2013 and 2014, we will adjust the sampling size of yellow taxi and green taxi for each year, so that the size are proportional to their number of total rows per sum of yellow rows and green rows.  \n",
    "\n",
    "The total size of our subset data - sample for our taxi data set - will be ** 500,000 ** rows. (= 100,000 rows * 5 years)\n",
    "\n",
    "### 1. Read in yellow taxi trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source urls for yellow taxi trip data in NYC between 2010 and 2014 \n",
    "source = ['https://data.cityofnewyork.us/resource/74wj-s5ij.json', #[0] 2010 yellow taxi\n",
    "          'https://data.cityofnewyork.us/resource/uwyp-dntv.json', #[1] 2011 yellow taxi\n",
    "          'https://data.cityofnewyork.us/resource/kerk-3eby.json', #[2] 2012 yellow taxi\n",
    "          'https://data.cityofnewyork.us/resource/t7ny-aygi.json', #[3] 2013 yellow taxi\n",
    "          'https://data.cityofnewyork.us/resource/h4pe-ymjc.json', #[4] 2013 green taxi\n",
    "          'https://data.cityofnewyork.us/resource/gkne-dk5s.json', #[5] 2014 yellow taxi\n",
    "          'https://data.cityofnewyork.us/resource/7j25-xd5y.json'] #[6] 2014 green taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 19)\n"
     ]
    }
   ],
   "source": [
    "# read 2010 yellow taxi data\n",
    "YTD_10_CRD = source[0] + '?vendorid=VTS&payment_type=CRD&$limit=50000'\n",
    "YTD_10_CSH = source[0] + '?vendorid=VTS&payment_type=CSH&$limit=50000'\n",
    "Y10CRD = pd.read_json(YTD_10_CRD)  # 50,000 rows\n",
    "Y10CSH = pd.read_json(YTD_10_CSH)  # 50,000 rows\n",
    "taxi_data_10 = Y10CRD.append(Y10CSH)\n",
    "print(taxi_data_10.shape) # 100,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 19)\n"
     ]
    }
   ],
   "source": [
    "# read 2011 yellow taxi data\n",
    "YTD_11_CRD = source[1] + '?vendorid=VTS&payment_type=CRD&$limit=50000'\n",
    "YTD_11_CSH = source[1] + '?vendorid=VTS&payment_type=CSH&$limit=50000'\n",
    "Y11CRD = pd.read_json(YTD_11_CRD)  # 50,000 rows\n",
    "Y11CSH = pd.read_json(YTD_11_CSH)  # 50,000 rows\n",
    "taxi_data_11 = Y11CRD.append(Y11CSH)\n",
    "print(taxi_data_11.shape) # 100,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 19)\n"
     ]
    }
   ],
   "source": [
    "# read 2012 yellow taxi data\n",
    "YTD_12_CRD = source[2] + '?vendorid=VTS&payment_type=CRD&$limit=50000'\n",
    "YTD_12_CSH = source[2] + '?vendorid=VTS&payment_type=CSH&$limit=50000'\n",
    "Y12CRD = pd.read_json(YTD_12_CRD)  # 50,000 rows\n",
    "Y12CSH = pd.read_json(YTD_12_CSH)  # 50,000 rows\n",
    "taxi_data_12 = Y12CRD.append(Y12CSH)\n",
    "print(taxi_data_12.shape) # 100,000 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read 2013 data from both yellow taxi source and green taxi source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93520, 19)\n"
     ]
    }
   ],
   "source": [
    "# for 2013 samples, \n",
    "\n",
    "# read 93,520 rows from yellow taxi, then\n",
    "YTD_13_CRD = source[3] + '?vendorid=VTS&payment_type=CRD&$limit=46760'\n",
    "YTD_13_CSH = source[3] + '?vendorid=VTS&payment_type=CSH&$limit=46760'\n",
    "Y13CRD = pd.read_json(YTD_13_CRD)  # 46,760 rows\n",
    "Y13CSH = pd.read_json(YTD_13_CSH)  # 46,760 rows\n",
    "yellow13 = Y13CRD.append(Y13CSH)\n",
    "print(yellow13.shape) # 93,520 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6480, 19)\n"
     ]
    }
   ],
   "source": [
    "# read the rest 6,480 rows from green taxi\n",
    "GTD_13_CRD = source[4] + '?vendorid=2&payment_type=1&$limit=3240'\n",
    "GTD_13_CSH = source[4] + '?vendorid=2&payment_type=2&$limit=3240'\n",
    "G13CRD = pd.read_json(GTD_13_CRD)  # 3,240 rows\n",
    "G13CSH = pd.read_json(GTD_13_CSH)  # 3,240 rows\n",
    "green13 = G13CRD.append(G13CSH)\n",
    "print(green13.shape) # 6,480 rows => total 100,000 rows for 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read 2014 data from both yellow taxi source and green taxi source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91266, 17)\n"
     ]
    }
   ],
   "source": [
    "# for 2014 samples, \n",
    "\n",
    "# read 91,266 rows from yellow taxi, then\n",
    "YTD_14_CRD = source[5] + '?vendor_id=VTS&payment_type=CRD&$limit=45633'\n",
    "YTD_14_CSH = source[5] + '?vendor_id=VTS&payment_type=CSH&$limit=45633'\n",
    "Y14CRD = pd.read_json(YTD_14_CRD)  # 45,633 rows\n",
    "Y14CSH = pd.read_json(YTD_14_CSH)  # 45,633 rows\n",
    "yellow14 = Y14CRD.append(Y14CSH)\n",
    "print(yellow14.shape) # 91,266 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8734, 19)\n"
     ]
    }
   ],
   "source": [
    "# read the rest 8,734 rows from green taxi\n",
    "GTD_14_CRD = source[6] + '?vendorid=2&payment_type=1&$limit=4367'\n",
    "GTD_14_CSH = source[6] + '?vendorid=2&payment_type=2&$limit=4367'\n",
    "G14CRD = pd.read_json(GTD_14_CRD)  # 4,367 rows\n",
    "G14CSH = pd.read_json(GTD_14_CSH)  # 4,367 rows\n",
    "green14 = G14CRD.append(G14CSH)\n",
    "print(green14.shape) # 8,734 rows => total 100,000 rows for 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess the taxi data\n",
    "** 1) Fix different column names. **\n",
    "\n",
    "The columns in the *Green taxi data-set* contains columns that are identical to the columns in yellow taxi dataset but with different column name; so we want to make sure that the column names are the same so that we can append the the two data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Difference in 2013 dataset =\n",
      "\n",
      "Yellow - Green: \n",
      "\n",
      " ['tpep_dropoff_datetime', 'dropoff_location', 'pickup_location', 'tpep_pickup_datetime']\n",
      "\n",
      "Green - Yellow: \n",
      "\n",
      " ['lpep_dropoff_datetime', 'trip_type', 'store_and_fwd_flag', 'lpep_pickup_datetime']\n",
      "\n",
      "= Difference in 2014 dataset =\n",
      "\n",
      "Yellow - Green: \n",
      "\n",
      " ['vendor_id', 'imp_surcharge', 'pickup_datetime', 'rate_code', 'dropoff_datetime']\n",
      "\n",
      "Green - Yellow: \n",
      "\n",
      " ['lpep_dropoff_datetime', 'vendorid', 'trip_type', 'store_and_fwd_flag', 'extra', 'lpep_pickup_datetime', 'ratecodeid']\n"
     ]
    }
   ],
   "source": [
    "# observe the difference in column names of yellow taxi data and green taxi data\n",
    "def see_column_name_diffs():\n",
    "    yellow_cols13 = yellow13.columns.values.tolist()\n",
    "    green_cols13 = green13.columns.values.tolist()\n",
    "\n",
    "    diff_cols1 = list(set(yellow_cols13) - set(green_cols13))\n",
    "    diff_cols2 = list(set(green_cols13) - set(yellow_cols13))\n",
    "\n",
    "    yellow_cols14 = yellow14.columns.values.tolist()\n",
    "    green_cols14 = green14.columns.values.tolist()\n",
    "\n",
    "    diff_cols3 = list(set(yellow_cols14) - set(green_cols14))\n",
    "    diff_cols4 = list(set(green_cols14) - set(yellow_cols14))\n",
    "\n",
    "    print(\"= Difference in 2013 dataset =\")\n",
    "    print(\"\\nYellow - Green: \\n\\n\", diff_cols1)\n",
    "    print(\"\\nGreen - Yellow: \\n\\n\", diff_cols2)\n",
    "    print(\"\\n= Difference in 2014 dataset =\")\n",
    "    print(\"\\nYellow - Green: \\n\\n\", diff_cols3)\n",
    "    print(\"\\nGreen - Yellow: \\n\\n\", diff_cols4)\n",
    "    \n",
    "see_column_name_diffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list the dataset to match column names \n",
    "taxi_data_list = [yellow13, green13, yellow14, green14]\n",
    "\n",
    "# match column names for the useful columns \n",
    "for i in range(len(taxi_data_list)):\n",
    "    for j in taxi_data_list[i].columns.values:\n",
    "        if j == 'lpep_dropoff_datetime' or j == 'tpep_dropoff_datetime':\n",
    "            taxi_data_list[i].rename(columns={j: 'dropoff_datetime' }, inplace=True)\n",
    "            \n",
    "        if j == 'lpep_pickup_datetime'   or j == 'tpep_pickup_datetime':\n",
    "            taxi_data_list[i].rename(columns={j: 'pickup_datetime' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Difference in 2013 dataset =\n",
      "\n",
      "Yellow - Green: \n",
      "\n",
      " ['dropoff_location', 'pickup_location']\n",
      "\n",
      "Green - Yellow: \n",
      "\n",
      " ['trip_type', 'store_and_fwd_flag']\n",
      "\n",
      "= Difference in 2014 dataset =\n",
      "\n",
      "Yellow - Green: \n",
      "\n",
      " ['vendor_id', 'rate_code', 'imp_surcharge']\n",
      "\n",
      "Green - Yellow: \n",
      "\n",
      " ['trip_type', 'ratecodeid', 'store_and_fwd_flag', 'vendorid', 'extra']\n"
     ]
    }
   ],
   "source": [
    "# confirm the change\n",
    "see_column_name_diffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Make the data set contain only the columns we need.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dropoff_latitude', 'dropoff_longitude', 'dropoff_datetime',\n",
       "       'pickup_datetime', 'pickup_latitude', 'pickup_longitude', 'tip_amount',\n",
       "       'trip_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the columns \n",
    "def needed_col(dataset):\n",
    "    cols = ['dropoff_latitude', 'dropoff_longitude','dropoff_datetime' , 'pickup_datetime',\n",
    "            'pickup_latitude','pickup_longitude','tip_amount','trip_distance']\n",
    "    refined_data = pd.DataFrame(dataset, columns = cols)\n",
    "    return (refined_data)\n",
    "\n",
    "taxi_data_10 = needed_col(taxi_data_10)\n",
    "taxi_data_11 = needed_col(taxi_data_11)\n",
    "taxi_data_12 = needed_col(taxi_data_12)\n",
    "yellow13 = needed_col(yellow13)\n",
    "green13 = needed_col(green13)\n",
    "yellow14 = needed_col(yellow14)\n",
    "green14 = needed_col(green14)\n",
    "\n",
    "# test one\n",
    "taxi_data_10.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Append the green taxi dataset to yellow taxi dataset for 2013 and 2014.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 8)\n",
      "(100000, 8)\n"
     ]
    }
   ],
   "source": [
    "taxi_data_13 = yellow13.append(green13)\n",
    "print(taxi_data_13.shape) #(100000, 8) \n",
    "\n",
    "taxi_data_14 = yellow14.append(green14)\n",
    "print(taxi_data_14.shape) #(100000, 8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the preprocessed taxi data into csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "taxi_data_10.to_csv('taxi_data_csv_files/taxi_data_10.csv')\n",
    "taxi_data_11.to_csv('taxi_data_csv_files/taxi_data_11.csv')\n",
    "taxi_data_12.to_csv('taxi_data_csv_files/taxi_data_12.csv')\n",
    "taxi_data_13.to_csv('taxi_data_csv_files/taxi_data_13.csv')\n",
    "taxi_data_14.to_csv('taxi_data_csv_files/taxi_data_14.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DataScience-Project]",
   "language": "python",
   "name": "conda-env-DataScience-Project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
